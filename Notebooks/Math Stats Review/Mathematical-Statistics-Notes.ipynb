{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1516404-cbef-4056-a501-540d6e2ef45e",
   "metadata": {},
   "source": [
    "## __Notes on Mathematical Statistics__\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "Author:      Tyler J. Brough <br>\n",
    "Last Update: March 14, 2022 <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "This notebook is based on the following sources: \n",
    "\n",
    "* _Appendix C: Fundamentals of Mathematical Statistics_ in the book _Introductory Econometrics: A Modern Approach 5th Edition_ by Wooldridge \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c40765-a9c6-42ca-9b6f-1a89bd88a0b3",
   "metadata": {},
   "source": [
    "## __Introduction__\n",
    "\n",
    "<br>\n",
    "\n",
    "This is a review of fundamental mathematical statistics that will be\n",
    "essential for learning regression modeling. The coverage is based on\n",
    "Wooldridge.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Statistical inference** is the process of learning something about a\n",
    "population given a sample from that population. Using the tools of\n",
    "statistics we will seek to *infer* something about the population, given\n",
    "only a sample.\n",
    "\n",
    "<br>\n",
    "\n",
    "A **population** is a well defined group of subjects, such as\n",
    "individuals, firms, cities, etc.\n",
    "\n",
    "By learning, we mainly mean two things:\n",
    "\n",
    "-   Estimation\n",
    "\n",
    "-   Hypothesis Testing\n",
    "\n",
    "<br>\n",
    "\n",
    "An example of a population is all working adults in the US. Labor\n",
    "economists are interested in learning about the return to education,\n",
    "measured by the average increase in earnings given another year of\n",
    "education. It is impractical or impossible to gather data on the entire\n",
    "population, but she can obtain data on a subset of the population. Using\n",
    "the data collected a labor economist may report that her best estimate\n",
    "of the return to another year of education is $7.5\\%$. This is an\n",
    "example of a **point estimate**. Or she may report a range, such as \"the\n",
    "return to education is between $5.6\\%$ and $9.4\\%$.\" This is an example\n",
    "of an **interval estimate**.\n",
    "\n",
    "<br>\n",
    "\n",
    "An urban economist might want to know whether neighborhood crime watch\n",
    "programs are associated with lower crime rates. After comparing crime\n",
    "rates of neighborhoods with and without such programs in a sample from\n",
    "the population, he can draw one of two conclusions: neighborhood watch\n",
    "programs do affect crime, or they do not. This is an example of\n",
    "**hypothesis testing**.\n",
    "\n",
    "<br>\n",
    "\n",
    "The first step in statistical inference is to identify the population of\n",
    "interest. Once a population has been identified, a model for the\n",
    "population relationship of interest may be specified. Models involve\n",
    "probability distributions or features of probability distributions, and\n",
    "these depend on unknown parameters. **Parameters** are constants that\n",
    "determine the directions and strengths of relationships among variables.\n",
    "In the labor economics example, the parameter of interest is the return\n",
    "to education in the population.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa04779-052a-444b-a89a-c1d6c96a1a1a",
   "metadata": {},
   "source": [
    "## __Sampling__\n",
    "\n",
    "<br>\n",
    "\n",
    "Let $Y$ be a random variable representing a population with PDF\n",
    "$f(y; \\theta)$, which depends on a single parameter $\\theta$. The PDF is\n",
    "assumed to be known, except for $\\theta$. Different values of $\\theta$\n",
    "imply different population distributions, and therefore we are\n",
    "interested in $\\theta$. If we can obtain samples from the population we\n",
    "can learn something about $\\theta$.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Random sampling:**\n",
    "\n",
    "If $Y_{1}, Y_{2}, \\ldots Y_{n}$ are independent random variables with a\n",
    "common PDF $f(y; \\theta)$ then\n",
    "$\\left\\{Y_{1}, Y_{2}, \\ldots, Y_{n}\\right\\}$ is said to be a *random\n",
    "sample* from $f(y, \\theta)$ (a random sample represented by\n",
    "$f(y; \\theta)$).\n",
    "\n",
    "<br>\n",
    "\n",
    "When $\\left\\{Y_{1}, Y_{2}, \\ldots, Y_{n}\\right\\}$ is a random sample\n",
    "from $f(y, \\theta)$, we also say that the $Y_{i}$ are **independent and\n",
    "identically distributed** (or iid) random variables from $f(y; \\theta)$.\n",
    "\n",
    "<br>\n",
    "\n",
    "If family income is obtained for $n = 100$ families in the US, the\n",
    "incomes we observe will differ for each sample of $100$ that we choose.\n",
    "Once a sample is obtained we have a set of number\n",
    "$\\left\\{y_{1}, y_{2}, \\ldots, y_{3}\\right\\}$, which constitute the data\n",
    "that we work with.\n",
    "\n",
    "<br>\n",
    "\n",
    "Random samples from Bernoulli distributions are often used to illustrate\n",
    "statistical concepts. If $Y_{1}, Y_{2}, \\ldots, Y_{n}$ are iid\n",
    "Bernoulli($\\theta$), such that $P(Y_{i} = 1) = \\theta$ and\n",
    "$P(Y_{i} = 0) = 1 - \\theta$ then\n",
    "$\\left\\{Y_{1}, Y_{2}, \\ldots, Y_{n}\\right\\}$ constitute a random sample\n",
    "from a Bernoull($\\theta$) distribution.\n",
    "\n",
    "<br>\n",
    "\n",
    "Consider the airline example: Each $Y_{i}$ denotes whether or not\n",
    "passenger $i$ shows up. $\\theta$ is the probability that a randomly\n",
    "drawn individual from the population shows up.\n",
    "\n",
    "<br>\n",
    "\n",
    "For many applications, random samples can be assumed to be drawn from a\n",
    "normal distribution. If $\\left\\{Y_{1}, Y_{2}, \\ldots, Y_{n}\\right\\}$ is\n",
    "a random sample from the Normal($\\mu$, $\\sigma^{2}$) population, the\n",
    "population is characterized by two parameters, the mean $\\mu$ and the\n",
    "variance $\\sigma^{2}$.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Finite sample properties** \n",
    "\n",
    "_Finite sample properties_ are properties that hold for a sample of\n",
    "any size, no matter how small or large (sometimes called \"small sample\n",
    "properties\" to distinguish from \"asymptotic properties\").\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee3bc2-4e4b-4dbe-b1b3-cf8eddeaee3c",
   "metadata": {},
   "source": [
    "## Estimation and Estimators \n",
    "\n",
    "Given a random sample drawn from a population distribution that depends\n",
    "on an unknown parameter $\\theta$. An **estimator** of $\\theta$ is a rule\n",
    "that assigns each possible outcome of the sample a value of $\\theta$.\n",
    "The rule is specified before any sampling is carried out (regardless of\n",
    "the data collected).\n",
    "\n",
    "<br>\n",
    "\n",
    "Let $\\left\\{Y_{1}, Y_{2}, \\ldots, Y_{n}\\right\\}$ be a random sample from\n",
    "a population with mean $\\mu$. A natural estimator of $\\mu$ is the\n",
    "average of the random sample:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\bar{Y} = \\frac{1}{n}\\sum\\limits_{i=1}^{n} Y_{i}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\bar{Y}$ is called the **sample average**; unlike earlier when we\n",
    "defined the average as a descriptive statistics, $\\bar{Y}$ is now viewed\n",
    "as an estimator. Given any outcome of the random variables\n",
    "$Y_{1}, Y_{2}, \\ldots, Y_{n}$, we use the same rule to estimate $\\mu$:\n",
    "we average them. For actual outcomes\n",
    "$\\left\\{y_{1}, y_{2}, \\ldots, y_{n}\\right\\}$, the estimate is just the\n",
    "average in the sample.\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\bar{y} = \\frac{(y_{1} + y_{2} + \\cdots + y_{n})}{n}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "More generally an estimator $W$ of a parameter $\\theta$ can be expressed\n",
    "as:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "W = h(Y_{1}, Y_{2}, \\ldots, Y_{n})\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "for some known function $h$ of the random variables\n",
    "$Y_{1}, Y_{2}, \\ldots, Y_{n}$. $W$ is a random variable because it\n",
    "depends on the random sample: as we obtain different random samples from\n",
    "the population, the value of $W$ can change.\n",
    "\n",
    "<br>\n",
    "\n",
    "When a particular set of numbers\n",
    "$\\left\\{y_{1}, y_{2}, \\ldots, y_{n}\\right\\}$ is plugged into $h$, we\n",
    "obtain an *estimate* of $\\theta$, denoted\n",
    "$w = h(y_{1}, y_{2}, \\ldots, y_{n})$.\n",
    "\n",
    "<br>\n",
    "\n",
    "So we have that:\n",
    "\n",
    "-   $W$ is a point estimator\n",
    "\n",
    "-   $w$ is a point estimate\n",
    "\n",
    "<br>\n",
    "\n",
    "to evaluate estimation procedures we study various properties of the PDF\n",
    "of $W$. The distribution of an estimator is called its **sampling\n",
    "distribution**. In mathematical statistics, we study the sampling\n",
    "distributions of estimators.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Unbiasedness:** an estimator, $W$ of $\\theta$, is an unbiased\n",
    "estimator if\n",
    "\n",
    "<br>\n",
    "\n",
    "$$E(W) = \\theta$$\n",
    "\n",
    "<br>\n",
    "\n",
    "for all possible values of $\\theta$.\n",
    "\n",
    "<br>\n",
    "\n",
    "Remarks:\n",
    "\n",
    "-   If an estimator is unbiased, then its PDF has an expected value\n",
    "    equal to the parameter it is estimating. However, in any given\n",
    "    sample $E(W)$ may not equal $\\theta$.\n",
    "\n",
    "-   Rather, if we could indefinitely draw samples from the population,\n",
    "    getting an estimate each time, and then average these estimates over\n",
    "    all random samples we would obtain $\\theta$.\n",
    "\n",
    "-   This is just a thought experiment, because in reality we have only\n",
    "    one sample to work with. But this \"what if\" property is desirable\n",
    "    for estimators.\n",
    "    \n",
    "<br>\n",
    "\n",
    "If $W$ is a **biased estimator** of $\\theta$, its bias is defined as\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "Bias(W) = E(W) - \\theta\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Example: $\\bar{Y}$ is an unbiased estimator of the population mean,\n",
    "$\\mu$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    " E(\\bar{Y}) &= E\\left(\\frac{1}{n} \\sum\\limits_{i=1}^{n} Y_{i}    \\right) \\\\ \n",
    "            &= \\frac{1}{n} E\\left(\\sum\\limits_{i=1}^{n} Y_{i}    \\right) \n",
    "            = \\frac{1}{n} \\left( \\sum\\limits_{i=1}^{n} E(Y_{i}) \\right) \\\\\n",
    "            &= \\frac{1}{n} \\sum\\limits_{i=1}^{n} \\mu                     \n",
    "            = \\frac{1}{n} n \\mu                                         \n",
    "            = \\mu                                              \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Example: $s^{2}$ is an unbiased estimator of $\\sigma^{2}$.\n",
    "\n",
    "<br>\n",
    "\n",
    "Let $\\left\\{Y_{1}, Y_{1}, \\ldots, Y_{n}\\right\\}$ denote a random sample\n",
    "from the population with\n",
    "\n",
    "-   $E(Y) = \\mu$\n",
    "\n",
    "-   $Var(Y) \\sigma^{2}$\n",
    "\n",
    "then\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "s^{2} = \\frac{1}{n-1}\\sum\\limits_{i=1}^{n} (Y_{i} - \\bar{Y})^{2}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "This is usually called the **sample variance**.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Note:** the division by $n-1$ accounts for the fact that $\\mu$ is\n",
    "estimated by $\\bar{Y}$ and not known. If $\\mu$ were known\n",
    "$\\frac{1}{n} \\sum\\limits_{i=1}^{n} (Y_{i} - \\mu)^{2}$, would be an\n",
    "unbiased estimator.\n",
    "\n",
    "<br>\n",
    "\n",
    "Unbiasedness has some weaknesses:\n",
    "\n",
    "-   Some very reasonable, even very good, estimates are not unbiased.\n",
    "\n",
    "-   Some unbiased estimates are quite poor.\n",
    "\n",
    "<br>\n",
    "\n",
    "For example:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "W = Y_{1} \\mbox{(i.e. discard all other observations)}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "It is an unbiased estimator $E(Y_{1}) = \\mu$.\n",
    "\n",
    "<br>\n",
    "\n",
    "Example: If $n = 100$, we have one hundred observation of the random\n",
    "variable $Y$, but we discard all but the first to estimate $E(Y)$.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "### __Sampling Variance__\n",
    "\n",
    "The weaknesses of unbiasedness show that we need additional criteria to\n",
    "evaluate estimators. Unbiasedness ensures that the sampling distribution\n",
    "of an estimator has a mean value equal to the parameter it is\n",
    "estimating.\n",
    "\n",
    "<br>\n",
    "\n",
    "We also want to know how spread out it is. The variance of an estimator\n",
    "is called its **sampling variance** because it is the variance\n",
    "associated with the sampling distribution.\n",
    "\n",
    "<br>\n",
    "\n",
    "Example: \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    " Var(\\bar{Y}) &= Var\\left(\\frac{1}{n} \\sum\\limits_{i=1}^{n} Y_{i} \\right) \\\\\n",
    "              &= \\frac{1}{n^{2}} Var\\left( \\sum\\limits_{i=1}^{n} Y_{i} \\right) = \n",
    "                 \\frac{1}{n^{2}} \\left( \\sum\\limits_{i=1}^{n} Var(Y_{i}) \\right) \\\\\n",
    "              &= \\frac{1}{n^{2}} \\left( \\sum\\limits_{i=1}^{n} \\sigma^{2} \\right) = \n",
    "                 \\frac{1}{n^{2}} n \\sigma^{2} = \\frac{1}{n} \\sigma^{2} \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "__Note:__ An important implication of $Var(\\bar{Y}) = \\frac{1}{n}\\sigma^{2}$ is that it can be made very close to zero by increasing the sample size $n$. \n",
    "\n",
    "<br>\n",
    "\n",
    "Amongst unbiased estimators we prefer the estimator with the smallest variance. \n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abcd4ec-3496-43db-9d21-28e78e11a1f0",
   "metadata": {},
   "source": [
    "### __Monte Carlo Simulation:__ Relative Efficiency of Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb7912f-a829-4257-96f8-04889cfb2dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare Ybar to Y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca44fa-f7e9-416c-984d-e24e330b7c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c7c701-f46f-49f3-973b-3806ab5cc022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06fa1758-7816-49c6-959c-65ac6ca3cb2c",
   "metadata": {},
   "source": [
    "## __Relative Efficiency__\n",
    "\n",
    "<br>\n",
    "\n",
    "If $W_{1}$ and $W_{2}$ are two unbiased estimators of $\\theta$, $W_{1}$ is efficient relative to $W_{2}$ when $Var(W_{1}) \\le Var(W_{2})$ for all $\\theta$. \n",
    "\n",
    "<br>\n",
    "\n",
    "__Example:__ $\\bar{Y}$ is efficient relative to $Y_{1}$ when seeking to estimate $\\mu$.\n",
    "\n",
    "<br>\n",
    "\n",
    "__Note:__ if we do not restrict attention to unbiased estimators comparing variances is meaningless.\n",
    "\n",
    "<br>\n",
    "\n",
    "__Example:__ \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W_{1} &= \\bar{Y} \\quad \\mbox{(unbiased)} \\\\\n",
    "& \\\\\n",
    "W_{2} &= 0 \\quad \\mbox{(biased)} \\rightarrow \\quad Bias(W_{2}) = -\\mu \\quad \\mbox{but has zero variance!}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "One way to compare estimators that are not necessarily unbiased is to compute the ___mean square error___ or __MSE__ of the estimators:\n",
    "\n",
    "<br>\n",
    "\n",
    "If $W$ is an estimator of $\\theta$ then\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "MSE(W) = E[(W - \\theta)^{2}]\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "MSE shows how far on average the estimator is away from $\\theta$\n",
    "\n",
    "<br>\n",
    "\n",
    "It can be shown that:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "MSE(W) = Var(W) + [Bias(W)]^{2}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "__Note:__ MSE trades of efficiency (variance) for bias\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa87ae5d-eb1b-4a69-a738-2c8d6b23a79f",
   "metadata": {},
   "source": [
    "## __Large Sample (Asymptotic) Properties of Estimators__\n",
    "\n",
    "<br>\n",
    "\n",
    "We saw with the estimator of $\\mu$, $W = Y_{1}$ that it was an unbiased, but poor estimator. One notable feature of $Y_{1}$ is that its variance is the same no matter what its sample size. It is reasonable to require that as ($n \\rightarrow \\infty$ that $\\sigma^{2} \\rightarrow 0$) sample size increases the estimator procedure improves. \n",
    "\n",
    "<br>\n",
    "\n",
    "__Example:__ $\\bar{Y}$ for estimation of population mean $\\mu$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "s^{2} &= Var(Y) = \\frac{1}{n-1}\\sum\\limits_{i=1}^{n} (Y_{i} - \\bar{Y})^{2} \\\\\n",
    "& \\\\\n",
    "& \\mbox{ as } \\quad n \\rightarrow \\infty, \\quad s^{2} \\rightarrow 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "With large sample properties of estimators we can rule out silly estimators (e.g. $W = Y_{1}$), as well as say something about estimators that are not unbiased, and whose variances are not easily found. \n",
    "\n",
    "<br>\n",
    "\n",
    "Asymptotic analysis involves approximating the features of the sampling distribution of an estimator. The approximations depend on the sample size. It is hard to say how _\"large\"_ a sample size is needed for asymptotic results to be appropriate. \n",
    "\n",
    "<br>\n",
    "\n",
    "Large sample properties have been known to work well for sample sizes as small as $n = 20$.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807762b4-0c35-41e4-b9eb-4330bce7c92f",
   "metadata": {},
   "source": [
    "## __Consistency__ \n",
    "\n",
    "<br>\n",
    "\n",
    "Let $W_{n}$ be an estimator of $\\theta$ based on a sample $\\{y_{1}, y_{2}, \\ldots, y_{n}\\}$ of size $n$\n",
    "\n",
    "<br>\n",
    "\n",
    "Then $W_{n}$ is a ___consistent estimator___ of $\\theta$ if for every $\\epsilon > 0$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "P(|W_{n} - \\theta| > \\epsilon) \\rightarrow 0 \\quad \\mbox{as} \\quad n \\rightarrow \\infty\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "If $W_{n}$ is consistent, we also say that $\\theta$ is the probability limit of $W_{n}$, written as \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "plim(W_{n}) = \\theta\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Interpretation: \n",
    "\n",
    "- The distribution of $W_{n}$ becomes more and more concentrated about $\\theta$, which means that for large sample sizes, $W_{n}$ is less and less likely to vary far from $\\theta$\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91de51a-2af6-42b9-aca2-1c66e0d92fc6",
   "metadata": {},
   "source": [
    "## __Monte Carlo Simulation:__ $\\bar{Y}$ a Consistent Estimator for $\\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6400a5f3-e747-47cd-9eb6-e74f2b642fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## See Consistency notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d43bd-a48a-4e6a-a67f-368c0023e60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f598ee38-9965-4a49-b047-af234f3b772c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd800fe2-9e5a-4f06-9ebc-a7c75b01c7be",
   "metadata": {},
   "source": [
    "## __Law of Large of Numbers__\n",
    "\n",
    "<br>\n",
    "\n",
    "Let $Y_{1}, Y_{2}, \\ldots, Y_{n}$ be independent, identically distributed random variables with mean $\\mu$, then\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "plim(\\bar{Y}_{n}) = \\mu\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Interpretation: \n",
    "\n",
    "- If we want to estimate the population average $\\mu$, we can get arbitrarily close to $\\mu$ by choosing a sufficiently large sample.\n",
    "\n",
    "<br>\n",
    "\n",
    "__Property PLIM1:__ Let $\\theta$ be a parameter and define a new parameter $\\gamma = g(\\theta)$, for some continuous function $g(\\theta)$.\n",
    "\n",
    "- Suppose that $plim(W_{n}) = \\theta$\n",
    "\n",
    "- Define an estimator $\\gamma$ by $G_{n} = g(W_{n})$\n",
    "\n",
    "- Then $plim(G_{n}) = \\gamma$\n",
    "\n",
    "<br>\n",
    "\n",
    "This often stated as: $plim[g(W_{n})] = g[plim(W_{n})]$ for a continuous fucntion $g(\\theta)$\n",
    "\n",
    "<br>\n",
    "\n",
    "__Examples:__ \n",
    "\n",
    "- $g(\\theta) = a + b \\theta$\n",
    "\n",
    "- $g(\\theta) = \\theta^{2}$\n",
    "\n",
    "- $g(\\theta) = \\frac{1}{\\theta}$\n",
    "\n",
    "- $g(\\theta) = \\sqrt{\\theta}$\n",
    "\n",
    "- $g(\\theta) = \\exp{\\theta}$\n",
    "\n",
    "- etc\n",
    "\n",
    "<br>\n",
    "\n",
    "__Property PLIM2:__ If $plim(T_{n}) = \\alpha$ and $plim(U_{n}) = \\beta$, then\n",
    "\n",
    "- __(i)__ $plim(T_{n} + U_{n}) = \\alpha + \\beta$\n",
    "\n",
    "- __(ii)__ $plim(T_{n} \\times U_{n}) = \\alpha \\times \\beta$\n",
    "\n",
    "- __(iii)__ $plim(T_{n}/U_{n}) = \\alpha / \\beta$, for $\\beta \\ne 0$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "__Example:__ \n",
    "\n",
    "- Let $\\{y_{1}, y_{2}, \\ldots, y_{n}\\}$ be a random sample of size $n$ on annual earnings from the population of workers with a high school education with population mean $\\mu_{Y}$.\n",
    "\n",
    "- Let $\\{z_{1}, z_{2}, \\ldots, z_{n}\\}$ be a random sample of size $n$ on annual earnings from the population of workers with a college education with population mean $\\mu_{Z}$\n",
    "\n",
    "- We wish to estimate the percentage difference in annual earnings between the two groups which is $\\gamma = 100\\frac{(\\mu_{Z} - \\mu_{Y})}{\\mu_{Y}}$ (percentage by which earnings for college grads differs from  high school grads)\n",
    "\n",
    "- Because $\\bar{Y}_{n}$ is consistent for $\\mu_{Y}$ and $\\bar{Z}_{n}$ is consistent for $\\mu_{Z}$ it follows that \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "G_{n} = 100 \\frac{(\\bar{Z}_{n} - \\bar{Y}_{n})}{\\bar{Y}_{n}}\n",
    "$$\n",
    "\n",
    "- is a consistent estimator of $\\gamma$\n",
    "\n",
    "<br>\n",
    "\n",
    "__Note:__ $G_{n}$ is not unbiased but maybe a good estimator as long as $n$ not _\"too\"_ small.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3c7c45-360c-440f-a824-a663940f0328",
   "metadata": {},
   "source": [
    "## __Asymptotic Normality__ \n",
    "\n",
    "- __NB:__ (Consistency is a property of point estimators)\n",
    "\n",
    "<br>\n",
    "\n",
    "Let $\\{Z_{n} : n = 1, 2, \\ldots\\}$ be a sequence of random variables, such that for all numbers $Z$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "P(Z_{n} \\le z) \\rightarrow \\Phi(z) \\quad \\mbox{as} \\quad n \\rightarrow\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "- __NB:__ (CDF of $Z_{n}$ gets closer and closer to the CDF of the standard normal as $n$ gets large)\n",
    "\n",
    "<br>\n",
    "\n",
    "Where $\\Phi(z)$ is the standard normal CDF\n",
    "\n",
    "<br>\n",
    "\n",
    "$Z_{n}$ is said to have an asymptotic standard normal distribution\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "Z_{n} \\overset{a}{\\sim} N(0,1)\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "When asymptotic normality holds for large $n$, we have the approximation\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "P(Z_{n} \\le z) \\approx \\Phi(z)\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "- i.e. probabilities concerning $Z_{n}$ can be approximated by the standard normal probabilities\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611991bf-c702-43c2-bed6-4aeecb39732f",
   "metadata": {},
   "source": [
    "## __The Central Limit Theorem__ \n",
    "\n",
    "<br>\n",
    "\n",
    "Let $\\{y_{1}, y_{2}, \\ldots, y_{n}\\}$ be a random sample with mean $\\mu$ and variance $\\sigma^{2}$, then\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "Z_{n} = \\frac{\\bar{Y}_{n} - \\mu}{\\sigma/\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "has an asymptotic standard normal distribution\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83ad99-f510-452a-b5b9-77ba512ff997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
